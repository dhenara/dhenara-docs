"use strict";(self.webpackChunkdhenara_docs=self.webpackChunkdhenara_docs||[]).push([[324],{8453:(n,e,t)=>{t.d(e,{R:()=>r,x:()=>s});var a=t(6540);const o={},i=a.createContext(o);function r(n){const e=a.useContext(i);return a.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:r(n.components),a.createElement(i.Provider,{value:e},n.children)}},8812:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>d,contentTitle:()=>s,default:()=>c,frontMatter:()=>r,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"getting-started/quick-start","title":"Quick Start with Dhenara","description":"This guide will help you get up and running with Dhenara quickly. We\'ll create a simple application that interacts with an AI model to generate text.","source":"@site/docs/getting-started/quick-start.md","sourceDirName":"getting-started","slug":"/getting-started/quick-start","permalink":"/getting-started/quick-start","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"docsSidebar","previous":{"title":"Installing Dhenara","permalink":"/getting-started/installation"},"next":{"title":"Key Concepts in Dhenara","permalink":"/getting-started/key-concepts"}}');var o=t(4848),i=t(8453);const r={sidebar_position:3},s="Quick Start with Dhenara",d={},l=[{value:"Setup",id:"setup",level:2},{value:"Basic Text Generation",id:"basic-text-generation",level:2},{value:"Streaming Text Generation",id:"streaming-text-generation",level:2},{value:"Using the Synchronous Interface",id:"using-the-synchronous-interface",level:2},{value:"Working with Images",id:"working-with-images",level:2},{value:"Next Steps",id:"next-steps",level:2}];function p(n){const e={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,i.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"quick-start-with-dhenara",children:"Quick Start with Dhenara"})}),"\n",(0,o.jsx)(e.p,{children:"This guide will help you get up and running with Dhenara quickly. We'll create a simple application that interacts with an AI model to generate text."}),"\n",(0,o.jsx)(e.h2,{id:"setup",children:"Setup"}),"\n",(0,o.jsx)(e.p,{children:"First, make sure you have Dhenara installed:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"pip install dhenara\n"})}),"\n",(0,o.jsx)(e.p,{children:"You'll need API credentials for at least one of the supported AI providers. For this example, we'll use OpenAI."}),"\n",(0,o.jsx)(e.h2,{id:"basic-text-generation",children:"Basic Text Generation"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import asyncio\nfrom dhenara.ai import AIModelClient, AIModelCallConfig\nfrom dhenara.ai.types.genai.ai_model import AIModelAPI, AIModelEndpoint\nfrom dhenara.ai.types.external_api import AIModelAPIProviderEnum\nfrom dhenara.ai.types.genai.foundation_models import FoundationModelFns\n\nasync def main():\n    # Get a pre-configured foundation model\n    gpt4o = FoundationModelFns.get_foundation_model("gpt-4o")\n\n    # Set up API credentials\n    api = AIModelAPI(\n        provider=AIModelAPIProviderEnum.OPEN_AI,\n        api_key="your-api-key-here"\n    )\n\n    # Create an endpoint combining the model and API\n    endpoint = AIModelEndpoint(\n        api=api,\n        ai_model=gpt4o\n    )\n\n    # Configure the API call\n    config = AIModelCallConfig(\n        max_output_tokens=500,\n        streaming=False\n    )\n\n    # Create a prompt\n    prompt = {\n        "role": "user",\n        "content": "Explain the importance of documentation in software development"\n    }\n\n    # Generate a response\n    async with AIModelClient(endpoint, config) as client:\n        response = await client.generate(prompt=prompt)\n\n        if response.chat_response:\n            print(response.chat_response.choices[0].contents[0].get_text())\n\n# Run the async function\nasyncio.run(main())\n'})}),"\n",(0,o.jsx)(e.h2,{id:"streaming-text-generation",children:"Streaming Text Generation"}),"\n",(0,o.jsx)(e.p,{children:"For a more interactive experience, enable streaming:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import asyncio\nfrom dhenara.ai import AIModelClient, AIModelCallConfig\nfrom dhenara.ai.types.genai.ai_model import AIModelAPI, AIModelEndpoint\nfrom dhenara.ai.types.external_api import AIModelAPIProviderEnum\nfrom dhenara.ai.types.genai.foundation_models import FoundationModelFns\n\nasync def main():\n    # Get a pre-configured foundation model\n    gpt4o = FoundationModelFns.get_foundation_model("gpt-4o")\n\n    # Set up API credentials\n    api = AIModelAPI(\n        provider=AIModelAPIProviderEnum.OPEN_AI,\n        api_key="your-api-key-here"\n    )\n\n    # Create an endpoint combining the model and API\n    endpoint = AIModelEndpoint(\n        api=api,\n        ai_model=gpt4o\n    )\n\n    # Configure the API call with streaming\n    config = AIModelCallConfig(\n        max_output_tokens=500,\n        streaming=True\n    )\n\n    # Create a prompt\n    prompt = {\n        "role": "user",\n        "content": "Write a short poem about programming"\n    }\n\n    # Generate a streaming response\n    async with AIModelClient(endpoint, config) as client:\n        response = await client.generate(prompt=prompt)\n\n        if response.async_stream_generator:\n            async for chunk, final_response in response.async_stream_generator:\n                if chunk:\n                    # Process each chunk as it arrives\n                    for delta in chunk.data.choice_deltas:\n                        for content_delta in delta.content_deltas:\n                            print(content_delta.get_text_delta(), end="", flush=True)\n                if final_response:\n                    # Handle the final consolidated response\n                    print("\\n\\nStream completed!")\n\n# Run the async function\nasyncio.run(main())\n'})}),"\n",(0,o.jsx)(e.h2,{id:"using-the-synchronous-interface",children:"Using the Synchronous Interface"}),"\n",(0,o.jsx)(e.p,{children:"If you prefer a synchronous interface:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'from dhenara.ai import AIModelClientSync, AIModelCallConfig\nfrom dhenara.ai.types.genai.ai_model import AIModelAPI, AIModelEndpoint\nfrom dhenara.ai.types.external_api import AIModelAPIProviderEnum\nfrom dhenara.ai.types.genai.foundation_models import FoundationModelFns\n\n# Get a pre-configured foundation model\nclaude = FoundationModelFns.get_foundation_model("claude-3-5-sonnet")\n\n# Set up API credentials\napi = AIModelAPI(\n    provider=AIModelAPIProviderEnum.ANTHROPIC,\n    api_key="your-anthropic-api-key"\n)\n\n# Create an endpoint\nendpoint = AIModelEndpoint(\n    api=api,\n    ai_model=claude\n)\n\n# Configure the call\nconfig = AIModelCallConfig()\n\n# Create a prompt\nprompt = {\n    "role": "user",\n    "content": "What are the most important things to know about AI safety?"\n}\n\n# Generate a response synchronously\nwith AIModelClientSync(endpoint, config) as client:\n    response = client.generate(prompt=prompt)\n\n    if response.chat_response:\n        print(response.chat_response.choices[0].contents[0].get_text())\n'})}),"\n",(0,o.jsx)(e.h2,{id:"working-with-images",children:"Working with Images"}),"\n",(0,o.jsx)(e.p,{children:"Dhenara also supports image generation:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import asyncio\nimport base64\nfrom PIL import Image\nimport io\nfrom dhenara.ai import AIModelClient, AIModelCallConfig\nfrom dhenara.ai.types.genai.ai_model import AIModelAPI, AIModelEndpoint\nfrom dhenara.ai.types.external_api import AIModelAPIProviderEnum\nfrom dhenara.ai.types.genai.foundation_models import FoundationModelFns\n\nasync def main():\n    # Get a pre-configured image generation model\n    dalle = FoundationModelFns.get_foundation_model("dall-e-3")\n\n    # Set up API credentials\n    api = AIModelAPI(\n        provider=AIModelAPIProviderEnum.OPEN_AI,\n        api_key="your-api-key-here"\n    )\n\n    # Create an endpoint\n    endpoint = AIModelEndpoint(\n        api=api,\n        ai_model=dalle\n    )\n\n    # Configure the call\n    config = AIModelCallConfig(\n        options={\n            "size": "1024x1024",\n            "quality": "standard",\n            "style": "vivid",\n            "response_format": "b64_json"\n        }\n    )\n\n    # Generate an image\n    async with AIModelClient(endpoint, config) as client:\n        response = await client.generate(\n            prompt="A futuristic city with flying cars and digital billboards"\n        )\n\n        if response.image_response:\n            # Get the base64 image data\n            image_content = response.image_response.choices[0].contents[0]\n\n            if image_content.content_format == "base64":\n                # Convert base64 to image\n                image_bytes = base64.b64decode(image_content.content_b64_json)\n                image = Image.open(io.BytesIO(image_bytes))\n\n                # Save the image\n                image.save("generated_image.png")\n                print("Image saved as generated_image.png")\n\n# Run the async function\nasyncio.run(main())\n'})}),"\n",(0,o.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n"]})}function c(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(p,{...n})}):p(n)}}}]);