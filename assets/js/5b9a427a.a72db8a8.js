"use strict";(self.webpackChunkdhenara_docs=self.webpackChunkdhenara_docs||[]).push([[8274],{8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var s=t(6540);const i={},a=s.createContext(i);function r(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(a.Provider,{value:n},e.children)}},9205:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"dhenara-ai/features/multi-turn-conversations","title":"Multi-Turn Conversations","description":"Multi-turn conversations with the Messages API","source":"@site/docs/dhenara-ai/features/multi-turn-conversations.md","sourceDirName":"dhenara-ai/features","slug":"/dhenara-ai/features/multi-turn-conversations","permalink":"/dhenara-ai/features/multi-turn-conversations","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Multi-Turn Conversations"},"sidebar":"dhenaraAiSidebar","previous":{"title":"Overview","permalink":"/dhenara-ai/features/features-overview"},"next":{"title":"Resource Configuration","permalink":"/dhenara-ai/features/resource-configuration"}}');var i=t(4848),a=t(8453);const r={title:"Multi-Turn Conversations"},o=void 0,l={},d=[{value:"Multi-turn conversations with the Messages API",id:"multi-turn-conversations-with-the-messages-api",level:2},{value:"Example",id:"example",level:2},{value:"Notes",id:"notes",level:2}];function c(e){const n={code:"code",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"multi-turn-conversations-with-the-messages-api",children:"Multi-turn conversations with the Messages API"}),"\n",(0,i.jsxs)(n.p,{children:["Dhenara supports multi-turn chat by keeping a list of message items. After each call, append the assistant response back\ninto the list using ",(0,i.jsx)(n.code,{children:"ChatResponse.to_message_item()"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"This approach works well for:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Chatbots and assistants"}),"\n",(0,i.jsx)(n.li,{children:"Workflows where tool calls appear mid-conversation"}),"\n",(0,i.jsx)(n.li,{children:"Switching models/providers while preserving a clean, provider-compatible message structure"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"example",children:"Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from dhenara.ai import AIModelClient\nfrom dhenara.ai.types import AIModelAPI, AIModelAPIProviderEnum, AIModelCallConfig, AIModelEndpoint\nfrom dhenara.ai.types.genai.dhenara.request import MessageItem, Prompt\nfrom dhenara.ai.types.genai.foundation_models.openai.chat import GPT5Mini\n\n\napi = AIModelAPI(\n    provider=AIModelAPIProviderEnum.OPEN_AI,\n    api_key="your_openai_api_key",\n)\n\nendpoint = AIModelEndpoint(api=api, ai_model=GPT5Mini)\n\nclient = AIModelClient(\n    model_endpoint=endpoint,\n    config=AIModelCallConfig(max_output_tokens=512),\n    is_async=False,\n)\n\nmessages: list[MessageItem] = []\n\nturns = [\n    "Tell me a short story about a robot learning to paint.",\n    "Continue the story and add a twist.",\n    "Conclude with an inspiring ending.",\n]\n\nfor user_text in turns:\n    messages.append(Prompt.with_text(user_text))\n\n    response = client.generate(\n        messages=messages,\n        instructions=["Be creative and keep it under 200 words."],\n    )\n\n    chat = response.chat_response\n    if not chat:\n        raise RuntimeError("No chat_response returned")\n\n    print("User:", user_text)\n    print("Assistant:\\n", chat.text())\n    print("-" * 60)\n\n    assistant_message = chat.to_message_item()\n    if assistant_message:\n        messages.append(assistant_message)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["If you use tool calling, appending ",(0,i.jsx)(n.code,{children:"to_message_item()"})," is important because it keeps the complete assistant message\n(text + tool calls) together."]}),"\n",(0,i.jsxs)(n.li,{children:["If you prefer ",(0,i.jsx)(n.code,{children:"prompt"}),"/",(0,i.jsx)(n.code,{children:"context"}),", that still works \u2014 the Messages API is recommended for multi-turn flows."]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}}}]);