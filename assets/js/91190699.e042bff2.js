"use strict";(self.webpackChunkdhenara_docs=self.webpackChunkdhenara_docs||[]).push([[4443],{7268:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"dhenara-ai/introduction","title":"Introduction","description":"Dhenara-AI is a powerful, flexible, and truly open-source Python framework for interacting with AI models from various","source":"@site/docs/dhenara-ai/introduction.md","sourceDirName":"dhenara-ai","slug":"/dhenara-ai/introduction","permalink":"/dhenara-ai/introduction","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"introduction","title":"Introduction","sidebar_position":1},"sidebar":"dhenaraAiSidebar","next":{"title":"Installation","permalink":"/dhenara-ai/getting-started/installation"}}');var i=r(4848),o=r(8453);const s={id:"introduction",title:"Introduction",sidebar_position:1},a="Introduction",l={},d=[{value:"Why Dhenara?",id:"why-dhenara",level:2},{value:"Key Features",id:"key-features",level:2},{value:"Example Usage",id:"example-usage",level:2},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"introduction",children:"Introduction"})}),"\n",(0,i.jsx)(n.p,{children:"Dhenara-AI is a powerful, flexible, and truly open-source Python framework for interacting with AI models from various\nproviders. Similar to LangChain but with a focus on simplicity and performance, Dhenara provides a unified interface to\nwork with models from OpenAI, Google AI, Anthropic, and other providers."}),"\n",(0,i.jsx)(n.h2,{id:"why-dhenara",children:"Why Dhenara?"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Genuinely Open Source"}),": Built from the ground up as a community resource, not an afterthought or internal tool"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Unified API"}),": Interact with different AI providers through a consistent interface"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Type Safety"}),": Built with Pydantic for robust type checking and validation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Easy Regeneration across Providers"}),": With a unified Pydantic output and built-in prompt formatting, send output\nfrom a model to any other model easily"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Streaming"}),": First-class support for streaming responses along with accumulated responses similar to non-streaming\nresponses"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Async Support"}),": Both synchronous and asynchronous interfaces for maximum flexibility"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Centralized Resource Management"}),": Configure all AI models and API credentials in one place with a simple YAML\nconfiguration"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Credential Security"}),": Keep sensitive API keys and credentials separate from application code"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dynamic Model Selection"}),": Switch between models and providers at runtime without reconfiguration"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Provider Abstraction"}),": Interact with foundation models regardless of which provider is serving them"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Foundation Models"}),": Pre-configured models with sensible defaults"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Test Mode"}),": Bring up your app with dummy responses for streaming and non-streaming generation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cost/Usage Data"}),": Derived cost and usage data along with responses, with optional charge for each model endpoint\nfor commercial deployment"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Community-Oriented Design"}),": An architecture separating API credentials, models, and configurations for flexible\ndeployment and scaling"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Open Source and Extensible"}),": Transparently designed codebase that encourages community contributions and extensions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Multiple Model Providers"}),": Support for OpenAI, Google AI, Anthropic, and DeepSeek"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Multiple API Providers"}),": Support for Vertex AI, Amazon Bedrock, Microsoft Azure AI along with OpenAI, Google AI &\nAnthropic"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Text and Image Generation"}),": Generate text or images through the same interface"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Streaming Support"}),": Stream responses for better user experience"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Accumulated Streaming Response"}),": Process stream responses in the same way you do with non-streaming"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"File Integration"}),": Easily incorporate files into your prompts"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cost Tracking"}),": Monitor token usage and associated costs"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Extensible Design"}),": Add custom models, providers, or model configurations"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"example-usage",children:"Example Usage"}),"\n",(0,i.jsx)(n.p,{children:"Here's a simple example of using Dhenara to interact with an AI model:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from dhenara.ai import AIModelClient\nfrom dhenara.ai.types import AIModelCallConfig, AIModelEndpoint\nfrom dhenara.ai.types.external_api import AIModelAPIProviderEnum\nfrom dhenara.ai.types.genai import AIModelAPI\nfrom dhenara.ai.types.genai.foundation_models.anthropic.chat import Claude37Sonnet\n\n# Create an API\napi = AIModelAPI(\n    provider=AIModelAPIProviderEnum.ANTHROPIC,\n    api_key="your_api_key",\n)\n\n# Create an endpoint using a pre-configured model\nmodel_endpoint = AIModelEndpoint(\n    api=api,\n    ai_model=Claude37Sonnet,\n)\n\n# Configure the api call\nconfig = AIModelCallConfig(\n    max_output_tokens=16000,\n    reasoning=True,  # Thinking/reasoning mode\n    max_reasoning_tokens=8000,\n    streaming=False,\n)\n\n# Create the client\nclient = AIModelClient(\n    model_endpoint=model_endpoint,\n    config=config,\n    is_async=False,\n)\n\n# Create a prompt\nprompt = {\n    "role": "user",\n    "content": "Explain quantum computing in simple terms",\n}\n\n# Generate a response\nresponse = client.generate(prompt=prompt)\n\n# If not streaming\nif response.chat_response:\n    print(response.chat_response.choices[0].contents[0].get_text())\n\n# If streaming\nelif response.stream_generator:\n    for chunk, _ in response.stream_generator:\n        if chunk:\n            print(\n                chunk.data.choice_deltas[0].content_deltas[0].get_text_delta(),\n                end="",\n                flush=True,\n            )\n\n'})}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Follow the ",(0,i.jsx)(n.a,{href:"/dhenara-ai/getting-started/installation",children:"Installation"})," guide to get started"]}),"\n",(0,i.jsxs)(n.li,{children:["Check out the ",(0,i.jsx)(n.a,{href:"/dhenara-ai/getting-started/quick-start",children:"Quick Start"})," for more examples"]}),"\n",(0,i.jsxs)(n.li,{children:["Learn about ",(0,i.jsx)(n.a,{href:"/dhenara-ai/getting-started/key-concepts",children:"Key Concepts"})," in Dhenara"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>a});var t=r(6540);const i={},o=t.createContext(i);function s(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);