"use strict";(self.webpackChunkdhenara_docs=self.webpackChunkdhenara_docs||[]).push([[3160],{1538:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"dhenara-ai/getting-started/quick-start","title":"Quick Start","description":"This guide will help you get up and running with Dhenara quickly. We\'ll create a simple application that interacts with an AI model to generate text.","source":"@site/docs/dhenara-ai/getting-started/quick-start.md","sourceDirName":"dhenara-ai/getting-started","slug":"/dhenara-ai/getting-started/quick-start","permalink":"/dhenara-ai/getting-started/quick-start","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Quick Start"},"sidebar":"dhenaraAiSidebar","previous":{"title":"Installation","permalink":"/dhenara-ai/getting-started/installation"},"next":{"title":"Key Concepts","permalink":"/dhenara-ai/getting-started/key-concepts"}}');var a=t(4848),s=t(8453);const o={title:"Quick Start"},r="Quick Start with Dhenara",c={},l=[{value:"Setup",id:"setup",level:2},{value:"Basic Text Generation",id:"basic-text-generation",level:2},{value:"Text Generation in Async Mode",id:"text-generation-in-async-mode",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"quick-start-with-dhenara",children:"Quick Start with Dhenara"})}),"\n",(0,a.jsx)(n.p,{children:"This guide will help you get up and running with Dhenara quickly. We'll create a simple application that interacts with an AI model to generate text."}),"\n",(0,a.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,a.jsx)(n.p,{children:"First, make sure you have Dhenara installed:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"pip install dhenara\n"})}),"\n",(0,a.jsx)(n.p,{children:"You'll need API credentials for at least one of the supported AI providers. For this example, we'll use Anthropic."}),"\n",(0,a.jsx)(n.h2,{id:"basic-text-generation",children:"Basic Text Generation"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'\nfrom dhenara.ai import AIModelClient\nfrom dhenara.ai.types import AIModelCallConfig, AIModelEndpoint\nfrom dhenara.ai.types.external_api import AIModelAPIProviderEnum\nfrom dhenara.ai.types.genai import AIModelAPI\nfrom dhenara.ai.types.genai.foundation_models.anthropic.chat import Claude37Sonnet\n\n# 1. Create an API\n# This can be used to create multiple model endpoints for the same API provider\napi = AIModelAPI(\n    provider=AIModelAPIProviderEnum.ANTHROPIC,\n    api_key="your_api_key", # TODO: Update with your Anthropic API Key\n)\n\n# 2. Select or create an AI model\n# You can either use the foundation models as it is, or create your own models\nmodel = Claude37Sonnet\n\n# Create the model endpoint\nmodel_endpoint = AIModelEndpoint(api=api, ai_model=model)\n\n# Create the client\nclient = AIModelClient(\n    model_endpoint=model_endpoint,\n    config=AIModelCallConfig(\n        max_output_tokens=16000,\n        reasoning=True,  # thinking/reasoning mode\n        max_reasoning_tokens=8000,  # Needed only if reasoning is set\n        streaming=False,\n    ),\n    is_async=False,  # Sync mode/ async mode\n)\n\n\nresponse = client.generate(\n    prompt={\n        "role": "user",\n        "content": "What are three ways to improve productivity?",\n    },\n    context=[],  # Optional history/context. Will show this on another example\n    instructions=[\n        "Be specific and actionable.",  # Optional instructions\n    ],\n)\n# Either print the whole response, or use below function to format it\n# print(response)\n\n\n# -----------------------------------------------------------------------------\n# To see formatted response, use below helper fn\ndef print_response(response):\n    for choice in response.chat_response.choices:\n        for content in choice.contents:\n            # Some formatting to differentiate contents\n            # With reasoning=True, same response will have multiple contents\n            print("-" * 80)\n            print(f"Type:: {content.type}")\n            print("-" * 80)\n            # Actual response text\n            print(f"{content.get_text()}")\n\n    # Optionally get the usage and cost for this call.\n    # Usage/Cost calculation is enabled by default, but can be disabled via setting\n    print("-" * 80)\n    print(f"Usage: {response.chat_response.usage}")\n    print(f"Usage Charge: {response.chat_response.usage_charge}")\n    print("-" * 80)\n\n\n# Call response  formatting fn\nprint_response(response)\n'})}),"\n",(0,a.jsx)(n.p,{children:"Output:"}),"\n",(0,a.jsx)("div",{className:"limited-height-code",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"--------------------------------------------------------------------------------\nType:: reasoning\n--------------------------------------------------------------------------------\nThe human is asking for three ways to improve productivity. I should provide a clear, concise response that outlines three effective strategies for improving productivity.\n\nI'll focus on well-established productivity methods that are:\n1. Evidence-based\n2. Practical for most people to implement\n3. Specific enough to be actionable\n\nHere are three solid approaches I can recommend:\n\n1. Time blocking and prioritization\n   - Setting aside specific time blocks for different tasks\n   - Using methods like the Eisenhower Matrix to prioritize tasks based on importance/urgency\n   - Focusing on completing the most important tasks first\n\n2. The Pomodoro Technique\n   - Working in focused intervals (typically 25 minutes) followed by short breaks\n   - Helps maintain concentration and prevent burnout\n   - Creates a sense of urgency that can boost focus\n\n3. Environment optimization and minimizing distractions\n   - Creating a workspace that minimizes interruptions\n   - Using tools to block digital distractions\n   - Batching similar tasks together to reduce context switching\n\nI'll explain each of these methods clearly with some practical implementation tips to make them actionable.\n--------------------------------------------------------------------------------\nType:: text\n--------------------------------------------------------------------------------\n# Three Ways to Improve Productivity\n\n## 1. Implement Time Blocking\nCreate a daily schedule that assigns specific time blocks for different tasks. Research shows this reduces decision fatigue and prevents multitasking. Try allocating your most challenging work to your peak energy hours, and set realistic time limits for each task.\n\n## 2. Use the Pomodoro Technique\nWork in focused intervals (typically 25 minutes) followed by short 5-minute breaks. After completing four intervals, take a longer 15-30 minute break. This method leverages our natural attention spans and prevents burnout while maintaining momentum.\n\n## 3. Minimize Distractions\nCreate an environment that supports focus by:\n- Silencing notifications and using apps that block distracting websites\n- Communicating boundaries to colleagues during deep work sessions\n- Organizing your workspace to reduce visual clutter and mental load\n\nEach of these strategies can be implemented immediately and adjusted to fit your specific work style and circumstances.\n--------------------------------------------------------------------------------\nUsage: total_tokens=533 prompt_tokens=50 completion_tokens=483\nUsage Charge: cost=0.007395 charge=None\n--------------------------------------------------------------------------------\n"})})}),"\n",(0,a.jsxs)(n.p,{children:["If you scroll downm you will see there are 2  items in ",(0,a.jsx)(n.code,{children:"contents"}),", one is ",(0,a.jsx)(n.code,{children:"text"})," type, which is the actual response of the model, and and additional ",(0,a.jsx)(n.code,{children:"reasoning"})," type with the ",(0,a.jsx)(n.em,{children:"think-text"}),". This is because we used a model with reasoning capabilities along with ",(0,a.jsx)(n.code,{children:"reasoning=True"}),". The good part is that, this is will be the same for all reasoning models that exposes their ",(0,a.jsx)(n.em,{children:"thinking"})," part to the user. (Eg: for Anthropic's ",(0,a.jsx)(n.em,{children:"Clause3.7"})," and ",(0,a.jsx)(n.em,{children:"DeepSeek-R1"})," )"]}),"\n",(0,a.jsxs)(n.p,{children:["If you print the output without calling the ",(0,a.jsx)(n.em,{children:"print_response()"})," function, it will look like,"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",metastring:'title="Output Without formatting"',children:"status=ExternalApiCallStatus(status='response_received_success', api_provider='anthropic', model='claude-3-7-sonnet', message='Output generated', code='success', http_status_code=200, data=None) chat_response=ChatResponse(model='claude-3-7-sonnet-20250219', provider='anthropic', api_provider='anthropic', usage=ChatResponseUsage(total_tokens=533, prompt_tokens=50, completion_tokens=483), usage_charge=UsageCharge(cost=0.007395, charge=None), choices=[ChatResponseChoice(index=0, finish_reason='end_turn', stop_sequence=None, contents=[ChatResponseReasoningContentItem(index=0, metadata={'signature': 'ErUBCkYIARgCIkBO2WeAlhVU2Er4BOR0QHUExtwtYE1CybJ3TjxsQVWJrQ1PvDZF9n1jNHkghhBHgMRFL5xRiXuBV+qqmUReiDIGEgzyx62PpTE+/XAidLsaDPhRX5iEm7q7tMtPyCIwDq6IXsKBCqTZcC3DbGy03RVPl+HQBAux424miePRqPRGACyk2IAEm6HRRV5nQ5zzKh2/sCntAG005ooBDkGv6FsU6tw4Of8Jni7mQadD+g=='}, storage_metadata={}, custom_metadata={}, type=<ChatResponseContentItemType.REASONING: 'reasoning'>, role='assistant', thinking_text=\"The human is asking for three ways to improve productivity. I should provide a clear, concise response that outlines three effective strategies for improving productivity.\\n\\nI'll focus on well-established productivity methods that are:\\n1. Evidence-based\\n2. Practical for most people to implement\\n3. Specific enough to be actionable\\n\\nHere are three solid approaches I can recommend:\\n\\n1. Time blocking and prioritization\\n   - Setting aside specific time blocks for different tasks\\n   - Using methods like the Eisenhower Matrix to prioritize tasks based on importance/urgency\\n   - Focusing on completing the most important tasks first\\n   \\n2. The Pomodoro Technique\\n   - Working in focused intervals (typically 25 minutes) followed by short breaks\\n   - Helps maintain concentration and prevent burnout\\n   - Creates a sense of urgency that can boost focus\\n   \\n3. Environment optimization and minimizing distractions\\n   - Creating a workspace that minimizes interruptions\\n   - Using tools to block digital distractions\\n   - Batching similar tasks together to reduce context switching\\n   \\nI'll explain each of these methods clearly with some practical implementation tips to make them actionable.\"), ChatResponseTextContentItem(index=1, metadata={}, storage_metadata={}, custom_metadata={}, type=<ChatResponseContentItemType.TEXT: 'text'>, role='assistant', text='# Three Ways to Improve Productivity\\n\\n## 1. Implement Time Blocking\\nCreate a daily schedule that assigns specific time blocks for different tasks. Research shows this reduces decision fatigue and prevents multitasking. Try allocating your most challenging work to your peak energy hours, and set realistic time limits for each task.\\n\\n## 2. Use the Pomodoro Technique\\nWork in focused intervals (typically 25 minutes) followed by short 5-minute breaks. After completing four intervals, take a longer 15-30 minute break. This method leverages our natural attention spans and prevents burnout while maintaining momentum.\\n\\n## 3. Minimize Distractions\\nCreate an environment that supports focus by:\\n- Silencing notifications and using apps that block distracting websites\\n- Communicating boundaries to colleagues during deep work sessions\\n- Organizing your workspace to reduce visual clutter and mental load\\n\\nEach of these strategies can be implemented immediately and adjusted to fit your specific work style and circumstances.')], metadata={})], metadata=AIModelCallResponseMetaData(streaming=False, duration_seconds=0, provider_metadata={'id': 'msg_01KegPt3ZuQNG2yqUYcszAL8'})) async_stream_generator=None sync_stream_generator=None image_response=None\n"})}),"\n",(0,a.jsx)(n.h2,{id:"text-generation-in-async-mode",children:"Text Generation in Async Mode"}),"\n",(0,a.jsx)(n.p,{children:"To use async in all API calls update your configuration in above example with  is_async=True`"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"\nclient = AIModelClient(\n    model_endpoint=model_endpoint,\n    config=AIModelCallConfig(\n        max_output_tokens=16000,\n        reasoning=True,  # thinking/reasoning mode\n        max_reasoning_tokens=8000,  # Needed only if reasoning is set\n        streaming=False,\n    ),\n    is_async=True,  # NOTE: This was changed\n)\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Then use the ",(0,a.jsx)(n.code,{children:"client.generate_async"})," as below."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# -----------------------------------------------------------------------------\n# For Async Mode:\n# NOTE: Set `is_async=True` in config above.\n# Then, generate text\nasync def generate_text_async():\n    response = await client.generate_async(\n        prompt={\n            "role": "user",\n            "content": "Explain quantum computing to a high school student.",\n        },\n        context=[],\n        instructions=[\n            "Be concise and focus on practical applications.",\n        ],\n    )\n    print_response(response)\n\n\n# Run the async function\nimport asyncio\n\nasyncio.run(generate_text_async())\n\n'})}),"\n",(0,a.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Explore ",(0,a.jsx)(n.a,{href:"../features/multi-turn-conversations",children:"Real-world Sample"})," that shows using dhenara for a multi-turn conversation"]}),"\n",(0,a.jsxs)(n.li,{children:["Learn about ",(0,a.jsx)(n.a,{href:"/dhenara-ai/features/features-overview",children:"features "})]}),"\n",(0,a.jsxs)(n.li,{children:["Look at a ",(0,a.jsx)(n.a,{href:"/dhenara-ai/samples/text-gen/streaming",children:"streaming sample"})]}),"\n"]}),"\n"]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>r});var i=t(6540);const a={},s=i.createContext(a);function o(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);