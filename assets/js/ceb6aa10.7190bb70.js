"use strict";(self.webpackChunkdhenara_docs=self.webpackChunkdhenara_docs||[]).push([[366],{5262:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"features/type-safety","title":"Type Safety","description":"Dhenara is designed with strong type safety principles at its core, ensuring robust and predictable behavior when working with AI models. This page explains our approach to type safety and unified response formats, and how this benefits your development workflow.","source":"@site/docs/features/type-safety.md","sourceDirName":"features","slug":"/features/type-safety","permalink":"/features/type-safety","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Type Safety"},"sidebar":"docsSidebar","previous":{"title":"Streaming Simplified","permalink":"/features/streaming-simplified"},"next":{"title":"Test Mode & Async Support","permalink":"/features/test-mode-and-async"}}');var r=t(4848),i=t(8453);const o={title:"Type Safety"},a="Type Safety and Unified Response Format",d={},c=[{value:"Type Safety with Pydantic Models",id:"type-safety-with-pydantic-models",level:2},{value:"Comprehensive Type Validation",id:"comprehensive-type-validation",level:3},{value:"Key Benefits of Dhenara&#39;s Type System",id:"key-benefits-of-dhenaras-type-system",level:3},{value:"Type-Safe Enumerations",id:"type-safe-enumerations",level:3},{value:"Unified Response Data Format",id:"unified-response-data-format",level:2},{value:"Consistent Response Structure",id:"consistent-response-structure",level:3},{value:"Unified Content Items",id:"unified-content-items",level:3},{value:"Standardized Streaming Support",id:"standardized-streaming-support",level:3},{value:"Unified Usage and Cost Tracking",id:"unified-usage-and-cost-tracking",level:3},{value:"Comparison with Other Libraries",id:"comparison-with-other-libraries",level:2},{value:"Versus LangChain",id:"versus-langchain",level:3},{value:"Versus Direct Provider SDKs",id:"versus-direct-provider-sdks",level:3},{value:"Benefits for Development Teams",id:"benefits-for-development-teams",level:2},{value:"Example: Working with Different Providers",id:"example-working-with-different-providers",level:2}];function l(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"type-safety-and-unified-response-format",children:"Type Safety and Unified Response Format"})}),"\n",(0,r.jsx)(n.p,{children:"Dhenara is designed with strong type safety principles at its core, ensuring robust and predictable behavior when working with AI models. This page explains our approach to type safety and unified response formats, and how this benefits your development workflow."}),"\n",(0,r.jsx)(n.h2,{id:"type-safety-with-pydantic-models",children:"Type Safety with Pydantic Models"}),"\n",(0,r.jsx)(n.h3,{id:"comprehensive-type-validation",children:"Comprehensive Type Validation"}),"\n",(0,r.jsx)(n.p,{children:"Dhenara uses Pydantic models throughout the library to enforce strict type validation, helping you catch errors early in the development process instead of at runtime."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from dhenara.ai.types.genai import ChatResponse, ChatResponseUsage\n\n# All models are properly typed and validated\nresponse = ChatResponse(\n    model="gpt-4",\n    provider=AIModelProviderEnum.OPEN_AI,\n    usage=ChatResponseUsage(\n        total_tokens=100,\n        prompt_tokens=50,\n        completion_tokens=50\n    ),\n    choices=[...]\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"key-benefits-of-dhenaras-type-system",children:"Key Benefits of Dhenara's Type System"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Early Error Detection"}),": Invalid data structures are caught immediately during object creation, not when trying to use the data."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Self-Documenting Code"}),": The type definitions serve as documentation, making it clear what data is expected."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"IDE Support"}),": Get autocompletion and type hints in your IDE, making development faster and more efficient."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Runtime Safety"}),": Prevent unexpected errors from propagating through your application."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"type-safe-enumerations",children:"Type-Safe Enumerations"}),"\n",(0,r.jsx)(n.p,{children:"Dhenara uses enumerations for all categorical values, providing compile-time and runtime validation:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from dhenara.ai.types.external_api import AIModelProviderEnum\n\n# Use strongly typed enumerations\nprovider = AIModelProviderEnum.OPEN_AI  # Safe, validated at runtime\nprovider = "some_random_string"  # Error! Caught by type checking\n'})}),"\n",(0,r.jsx)(n.h2,{id:"unified-response-data-format",children:"Unified Response Data Format"}),"\n",(0,r.jsx)(n.p,{children:"One of Dhenara's standout features is its unified response format across all AI providers, making it simple to switch between models or use multiple models in the same application."}),"\n",(0,r.jsx)(n.h3,{id:"consistent-response-structure",children:"Consistent Response Structure"}),"\n",(0,r.jsx)(n.p,{children:"Whether you're using OpenAI, Google AI, Anthropic, or any other provider, the response structure remains consistent:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# The format is the same whether using OpenAI, Google AI, Anthropic, etc.\nresponse = chat_client.generate(prompt=prompt)\nif response.chat_response:\n    # Access data the same way regardless of the provider\n    text = response.chat_response.choices[0].contents[0].text\n"})}),"\n",(0,r.jsx)(n.h3,{id:"unified-content-items",children:"Unified Content Items"}),"\n",(0,r.jsx)(n.p,{children:"All AI model responses are normalized into standardized content item types:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"ChatResponseTextContentItem"})," - For standard text responses"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"ChatResponseReasoningContentItem"})," - For model reasoning/thinking"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"ChatResponseToolCallContentItem"})," - For tool/function calls"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"ImageResponseContentItem"})," - For generated images"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This means you can easily process responses without worrying about provider-specific formats:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Works with any provider\nfor choice in response.chat_response.choices:\n    for content in choice.contents:\n        if content.type == "text":\n            print(content.text)\n        elif content.type == "reasoning":\n            print(f"Reasoning: {content.thinking_text}")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"standardized-streaming-support",children:"Standardized Streaming Support"}),"\n",(0,r.jsx)(n.p,{children:"Dhenara's streaming implementation works the same way across all providers:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'async with client as c:\n    response = await c.generate_async(prompt=prompt)\n    async for chunk, _ in response.async_stream_generator:\n        # Process streaming chunks consistently regardless of provider\n        if chunk and chunk.data:\n            for delta in chunk.data.choice_deltas:\n                for content_delta in delta.content_deltas:\n                    print(content_delta.get_text_delta(), end="")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"unified-usage-and-cost-tracking",children:"Unified Usage and Cost Tracking"}),"\n",(0,r.jsx)(n.p,{children:"Track token usage and costs consistently across providers:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Access usage data the same way for all providers\nif response.chat_response.usage:\n    print(f"Prompt tokens: {response.chat_response.usage.prompt_tokens}")\n    print(f"Completion tokens: {response.chat_response.usage.completion_tokens}")\n    print(f"Total tokens: {response.chat_response.usage.total_tokens}")\n\n    if response.chat_response.usage_charge:\n        print(f"Cost: ${response.chat_response.usage_charge.cost}")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"comparison-with-other-libraries",children:"Comparison with Other Libraries"}),"\n",(0,r.jsx)(n.h3,{id:"versus-langchain",children:"Versus LangChain"}),"\n",(0,r.jsx)(n.p,{children:"While LangChain provides a wide range of integrations, it often lacks strict type safety:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Feature"}),(0,r.jsx)(n.th,{children:"Dhenara"}),(0,r.jsx)(n.th,{children:"LangChain"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Type Safety"})}),(0,r.jsx)(n.td,{children:"Strong typing with Pydantic models throughout"}),(0,r.jsx)(n.td,{children:"Mixed, often relies on dictionaries or loosely typed objects"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Response Format"})}),(0,r.jsx)(n.td,{children:"Unified response structure across all providers"}),(0,r.jsx)(n.td,{children:"Different response formats for different providers"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Error Handling"})}),(0,r.jsx)(n.td,{children:"Structured error types with detailed information"}),(0,r.jsx)(n.td,{children:"Often passes through provider-specific errors"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Usage Tracking"})}),(0,r.jsx)(n.td,{children:"Consistent usage and cost tracking"}),(0,r.jsx)(n.td,{children:"Varies by integration"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"IDE Support"})}),(0,r.jsx)(n.td,{children:"Full autocompletion and type hints"}),(0,r.jsx)(n.td,{children:"Limited due to looser typing"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"versus-direct-provider-sdks",children:"Versus Direct Provider SDKs"}),"\n",(0,r.jsx)(n.p,{children:"Using provider SDKs directly can be challenging when working with multiple AI models:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Feature"}),(0,r.jsx)(n.th,{children:"Dhenara"}),(0,r.jsx)(n.th,{children:"Direct Provider SDKs"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Cross-Provider Compatibility"})}),(0,r.jsx)(n.td,{children:"Same code works across providers"}),(0,r.jsx)(n.td,{children:"Need different code for each provider"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Response Structure"})}),(0,r.jsx)(n.td,{children:"Normalized, consistent structure"}),(0,r.jsx)(n.td,{children:"Different structures for each provider"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Learning Curve"})}),(0,r.jsx)(n.td,{children:"Learn once, use everywhere"}),(0,r.jsx)(n.td,{children:"Learn each provider's unique API"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Type Safety"})}),(0,r.jsx)(n.td,{children:"Consistent type checking"}),(0,r.jsx)(n.td,{children:"Varies by provider"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"benefits-for-development-teams",children:"Benefits for Development Teams"}),"\n",(0,r.jsx)(n.p,{children:"Having a type-safe, unified API across providers offers significant advantages for teams:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reduced Cognitive Load"}),": Developers don't need to context-switch between different provider APIs"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Code Reusability"}),": Write code that works with any supported AI model"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Easy Provider Switching"}),": Compare models or switch providers without rewriting application code"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Safer Refactoring"}),": Type checking catches issues when changing code"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Better Collaboration"}),": Clear interfaces make it easier for team members to work together"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"example-working-with-different-providers",children:"Example: Working with Different Providers"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from dhenara.ai import AIModelClient\nfrom dhenara.ai.types.external_api import OpenAiMessageRoleEnum\n\n# Function that works with any provider\nasync def get_completion(client, question):\n    prompt = {\n        "role": OpenAiMessageRoleEnum.USER,\n        "content": question\n    }\n\n    response = await client.generate_async(prompt=prompt)\n\n    # Same access pattern regardless of the underlying provider\n    if response.chat_response:\n        return response.chat_response.choices[0].contents[0].text\n    return None\n\n# Works with OpenAI\nasync with AIModelClient(openai_endpoint) as client:\n    answer = await get_completion(client, "What is machine learning?")\n\n# Works with Anthropic without changing access code\nasync with AIModelClient(anthropic_endpoint) as client:\n    answer = await get_completion(client, "What is machine learning?")\n'})}),"\n",(0,r.jsx)(n.p,{children:"The type safety and unified response format in Dhenara make it an ideal choice for teams building production applications with AI, where predictability, reliability, and maintainability are crucial."})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var s=t(6540);const r={},i=s.createContext(r);function o(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);