"use strict";(self.webpackChunkdhenara_docs=self.webpackChunkdhenara_docs||[]).push([[5750],{8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>s});var o=t(6540);const i={},a=o.createContext(i);function r(e){const n=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),o.createElement(a.Provider,{value:n},e.children)}},8839:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>l});const o=JSON.parse('{"id":"dhenara-agent/guides/tutorials/single-shot-coder/part-1","title":"Part 1- Bringup","description":"In this first part of our tutorial, we\'ll build a simple \\"single-shot\\" coding assistant that can take a task","source":"@site/docs/dhenara-agent/guides/tutorials/single-shot-coder/part-1.md","sourceDirName":"dhenara-agent/guides/tutorials/single-shot-coder","slug":"/dhenara-agent/guides/tutorials/single-shot-coder/part-1","permalink":"/dhenara-agent/guides/tutorials/single-shot-coder/part-1","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Part 1- Bringup"},"sidebar":"dhenaraAgentSidebar","previous":{"title":"Command-Line Coding Assistant","permalink":"/dhenara-agent/guides/tutorials/command-line-coder/"},"next":{"title":"Part 1- Live Inputs","permalink":"/dhenara-agent/guides/tutorials/single-shot-coder/part-2"}}');var i=t(4848),a=t(8453);const r={title:"Part 1- Bringup"},s="Part 1: Single-Shot Implementation Flow",d={},l=[{value:"What is a Single-Shot Implementation?",id:"what-is-a-single-shot-implementation",level:2},{value:"Project Setup",id:"project-setup",level:2},{value:"Understanding the Project Structure",id:"understanding-the-project-structure",level:2},{value:"Creating the Types",id:"creating-the-types",level:2},{value:"Setup the context repo/folders",id:"setup-the-context-repofolders",level:2},{value:"Implementing Flow",id:"implementing-flow",level:2},{value:"Agent update",id:"agent-update",level:2},{value:"Update Runners",id:"update-runners",level:2},{value:"Running the agent",id:"running-the-agent",level:2},{value:"Debugging",id:"debugging",level:3},{value:"Fix and run",id:"fix-and-run",level:3},{value:"Understanding artifacts",id:"understanding-artifacts",level:2},{value:"Artifact files inside each node",id:"artifact-files-inside-each-node",level:3},{value:"Analysing Node artifacts results",id:"analysing-node-artifacts-results",level:2},{value:"FolderAnalyzerNode",id:"folderanalyzernode",level:3},{value:"AIModelNode Node",id:"aimodelnode-node",level:3},{value:"FileOperationNode",id:"fileoperationnode",level:3},{value:"Run in Live mode",id:"run-in-live-mode",level:2},{value:"Final Results",id:"final-results",level:2},{value:"AIModelNode Node",id:"aimodelnode-node-1",level:3},{value:"Troubleshooting",id:"troubleshooting",level:4},{value:"FileOperationNode",id:"fileoperationnode-1",level:3},{value:"What&#39;s Next?",id:"whats-next",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"part-1-single-shot-implementation-flow",children:"Part 1: Single-Shot Implementation Flow"})}),"\n",(0,i.jsx)(n.p,{children:'In this first part of our tutorial, we\'ll build a simple "single-shot" coding assistant that can take a task\ndescription, generate code, make the file changes and commit it. This will serve as the foundation for our more advanced\nagent in later parts.'}),"\n",(0,i.jsx)(n.h2,{id:"what-is-a-single-shot-implementation",children:"What is a Single-Shot Implementation?"}),"\n",(0,i.jsx)(n.p,{children:"A single-shot implementation is the simplest form of a coding assistant. It takes a task description, analyzes the\nrelevant files/folders for code context, and generates code to implement the task in one go. Unlike more complex agents,\nit doesn't break the task down into smaller steps or create a plan\u2014it simply executes the implementation directly."}),"\n",(0,i.jsx)(n.h2,{id:"project-setup",children:"Project Setup"}),"\n",(0,i.jsx)(n.p,{children:"Let's start by setting up our project structure:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Create a new project (or use an existing one):"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"python3 -m venv .venv\nsource .venv/bin/activate\n\n(.venv) $ dhenara startproject dev_agents\n\nInitializing Git.\n\u2705 Project 'dev_agents' created successfully!\n  - Project identifier: dev_agents\n  - Location: <path>.../dev_agents\n\nNext steps:\n  1. cd dev_agents\n  2. dhenara create agent <agent_name>\n(.venv) $\n"})}),"\n",(0,i.jsxs)(n.ol,{start:"2",children:["\n",(0,i.jsxs)(n.li,{children:["Create a new agent for our CLI coder. Let's name it as ",(0,i.jsx)(n.em,{children:"autocoder"}),":"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"(.venv) $ cd dev_agents\n(.venv) $ dhenara create agent autocoder\n\u2705 Agent 'autocoder' created successfully!\n  - Identifier: autocoder\n  - Location: /Users/ajithjose/Work/web_development/django/project_repos/20_agents/demos/dev_agents/src/agents/autocoder\n  - Command to run:  dhenara run agent autocoder\n(.venv) $\n"})}),"\n",(0,i.jsx)(n.h2,{id:"understanding-the-project-structure",children:"Understanding the Project Structure"}),"\n",(0,i.jsx)(n.p,{children:"This will create the following structure:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"src/\n\u251c\u2500\u2500 agents/\n\u2502   \u2514\u2500\u2500 autocoder/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 agent.py\n\u2502       \u251c\u2500\u2500 flow.py\n\u2502       \u2514\u2500\u2500 handler.py\n\u2514\u2500\u2500 runners/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 defs.py\n    \u2514\u2500\u2500 autocoder.py\n"})}),"\n",(0,i.jsxs)(n.p,{children:["The files come with a pre-built simple chatbot agent. We will update them one by one. To organize it better, let's\ndelete the ",(0,i.jsx)(n.code,{children:"flow.py"})," and create a ",(0,i.jsx)(n.code,{children:"flows"})," directory with an init file:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"rm src/agents/autocoder/flow.py\nmkdir src/agents/autocoder/flows\ntouch src/agents/autocoder/flows/__init__.py\n"})}),"\n",(0,i.jsx)(n.h2,{id:"creating-the-types",children:"Creating the Types"}),"\n",(0,i.jsx)(n.p,{children:"Before we implement our flow, let's create a file to define the types our agent will use. DAD and Dhenara-AI come with\nstrong type checking using Pydantic, but we still need to define the types which need to be passed to AI model API calls\nfor structured output generation."}),"\n",(0,i.jsxs)(n.p,{children:["In the ",(0,i.jsx)(n.code,{children:"autocoder"})," directory, create a ",(0,i.jsx)(n.code,{children:"types.py"})," file:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"touch src/agents/autocoder/types.py\n"})}),"\n",(0,i.jsx)(n.p,{children:"and add below to this file."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from dhenara.agent.dsl.inbuilt.flow_nodes.defs.types import FileOperation\nfrom pydantic import BaseModel, Field\n\nclass TaskImplementation(BaseModel):\n    """\n    Contains the concrete file operations to implement a specific task of the plan.\n    This is the output generated after analyzing the context specified in the TaskSpec.\n    """\n\n    task_id: str | None = Field(\n        default=None,\n        description=("ID of the corresponding TaskSpec that this implements if it was given in the inputs"),\n    )\n    file_operations: list[FileOperation] | None = Field(\n        default_factory=list,\n        description="Ordered list of file operations to execute for this implementation task",\n    )\n    execution_commands: list[dict] | None = Field(\n        None,\n        description="Optional shell commands to run after file operations (e.g., for build or setup)",\n    )\n    verification_commands: list[dict] | None = Field(\n        None,\n        description="Optional commands to verify the changes work as expected",\n    )\n\n'})}),"\n",(0,i.jsx)(n.p,{children:"We created this model so that we can configure this as the structured output from LLM API calls later. The dhenara-ai\npackage will take this Pydantic model and convert it to the schema/format required by the API provider you use in the\nAIModelCallNode later."}),"\n",(0,i.jsxs)(n.p,{children:["If you are not familiar with structured outputs, don't worry. You only need to know that above ",(0,i.jsx)(n.em,{children:"TaskImplementation"})," is\nthe format in which we want the output from any LLM API calls. Say you asked a question, and LLM thinks you need to\ncreate/delete few files, it will respond in below format."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "task_id": null,\n  "file_operations": [\n    {\n      "type": "create_file",\n      "path": "dhenara_fe_nextjs/src/components/common/ExternalLinkIcon.tsx",\n      "content": "import React from \'react\';.."\n    },\n    {\n      "type": "delete_file",\n      "path": "dhenara_fe_nextjs/src/components/common/SmartLink.tsx"\n    },\n    {\n      "type": "create_file",\n      "path": "dhenara_fe_nextjs/src/components/common/SmartLink.tsx",\n      "paths": null,\n      "content": "// INFO:\\n//  Component that determines..."\n    },\n    {\n      "type": "create_file",\n      "path": "dhenara_fe_nextjs/src/components/home/ProductCard.tsx",\n      "content": "import { SmartLink } from \'@/components/common/SmartLink\'..."\n    }\n  ],\n  "execution_commands": null,\n  "verification_commands": null\n}\n'})}),"\n",(0,i.jsx)(n.p,{children:"You are defining the structure of the output in which you expect the response, in a more convenient way than using JSON\nschema by creating a Pydantic Model."}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["Here ",(0,i.jsx)(n.code,{children:"FileOperation"})," is a built-in type in DAD. We need to use that instead of defining a custom type here, so that you\ncan use the LLM output directly inside a FileOperationNode later."]})}),"\n",(0,i.jsx)(n.h2,{id:"setup-the-context-repofolders",children:"Setup the context repo/folders"}),"\n",(0,i.jsx)(n.p,{children:"We will use this autocoder agent to make changes in any project repo for any programming language. It can even create a\ncode repo from scratch. First, we will start with updating an existing repo."}),"\n",(0,i.jsxs)(n.p,{children:["We need to pass the relevant context to the LLM in order to respond with the right answers. Therefore, every time when\nyou ask to do a task on your project repo (not this DAD project, your actual work project), you will specify which files\nneed to be sent to the LLM. In a more sophisticated flow, you will use an additional LLM API call before the actual code\ngeneration to decide which files/folders need to be read and sent to LLM so that it gets the right context. We will do\nthis later when we enhance this flow with a ",(0,i.jsx)(n.em,{children:"Planner"})," flow."]}),"\n",(0,i.jsx)(n.p,{children:"For now, each time you run this agent, you will specify which files/folders need to be read and sent to LLM, because you\nknow your repo better."}),"\n",(0,i.jsxs)(n.p,{children:["We will do this by using a ",(0,i.jsx)(n.code,{children:"FolderAnalyzerNode"})," in our flow. In order to read selected files/folders of your project,\nlet's copy it in a directory inside our DAD project. The best place to do it is inside our ",(0,i.jsx)(n.code,{children:"runs"})," directory. This is a\ndirectory which is ",(0,i.jsx)(n.strong,{children:"not"})," tracked under DAD's git repo; it's our artifacts directory. This will be created when you run\nan agent for the first time by using the ",(0,i.jsx)(n.code,{children:"dhenara run agent"})," command, but in order to copy/clone your actual project,\nlet's create it right now and copy your project there."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"mkdir runs\n"})}),"\n",(0,i.jsxs)(n.admonition,{type:"warning",children:[(0,i.jsxs)(n.p,{children:["Do not confuse the ",(0,i.jsx)(n.em,{children:"runs"})," directory with ",(0,i.jsx)(n.em,{children:"runners"})," directory inside src. The ",(0,i.jsx)(n.em,{children:"runners"})," dir contains the essential\nsettings to run agents and is git tracked, but the ",(0,i.jsx)(n.em,{children:"runs"})," dir is our artifact directory, sitting directly under the DAD\nproject root."]}),(0,i.jsxs)(n.p,{children:["For every run command, a unique dir will be created inside ",(0,i.jsx)(n.em,{children:"runs"})," with artifacts, and you might want to clean up these\nwhen you run many iterations."]})]}),"\n",(0,i.jsxs)(n.p,{children:["Let's create a global directory to store all your projects. The idea behind creating a global dir inside runs is that\nyou can clone/copy multiple repos (e.g., a front-end repo, backend repo, and a documentation repo) and pass context from\nany of these in LLM calls. Here we are calling this as ",(0,i.jsx)(n.code,{children:"global_data"})," and this will sit directly inside our runs\ndirectory."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"mkdir runs/global_data\ncd runs/global_data\ngit clone <Your actual repo> <local_repo_name>\n# OR\n# Copy your project\n"})}),"\n",(0,i.jsx)(n.p,{children:"In our example, we are cloning the DAD docs repo, as this agent is for making updates in that repo. So we will use it\nlike:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"mkdir runs\ncd runs\ngit clone https://github.com/dhenara/dhenara-docs.git dhenara_docs\n"})}),"\n",(0,i.jsx)(n.h2,{id:"implementing-flow",children:"Implementing Flow"}),"\n",(0,i.jsxs)(n.p,{children:["Now, we will create an ",(0,i.jsx)(n.em,{children:"implementation flow"}),". It is nothing but our single shot agent flow. The reason we call it\nimplementation is, later in this tutorial, we will have additional flows like planner flow, and this single shot flow\nwill serve as implementation for the plan output."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"touch src/agents/autocoder/flows/implementation.py\n"})}),"\n",(0,i.jsx)(n.p,{children:"and update it with the code below:"}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["We have enabled the test mode in LLM API calls by setting ",(0,i.jsx)(n.code,{children:"test_mode=True"})," inside the ",(0,i.jsx)(n.code,{children:"AIModelNode"}),". This is a cool\nfeature that ",(0,i.jsx)(n.code,{children:"dhenara-ai"})," offers so that you can bring up your AI projects without losing money. We will start with test\nmode initially, and we will disable it later, when we know that our setup is completed correctly."]})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from dhenara.agent.dsl import (\n    PLACEHOLDER,\n    AIModelNode,\n    AIModelNodeSettings,\n    EventType,\n    FileOperationNode,\n    FileOperationNodeSettings,\n    FlowDefinition,\n    FolderAnalyzerNode,\n    FolderAnalyzerSettings,\n)\nfrom dhenara.agent.dsl.inbuilt.flow_nodes.defs.types import FolderAnalysisOperation\n\nfrom dhenara.ai.types import (\n    AIModelCallConfig,\n    ObjectTemplate,\n    Prompt,\n)\n\nfrom src.agents.autocoder.types import TaskImplementation\n\n\n\n# Initially, we will hard code the task_description,\n# but later we will use DAD\'s strong template system to accept it live\ntask_description = "Update the README file with relevant content"\n#task_description = "Your Task description"\n\n# Directory path where we analyze the folders\nglobal_data_directory = "$var{run_root}/global_data"\n\n# Create a FlowDefinition\nimplementation_flow = FlowDefinition()\n\n\n# 1. Dynamic Folder Analysis\nimplementation_flow.node(\n    "dynamic_repo_analysis",\n    FolderAnalyzerNode(\n        # pre_events=[EventType.node_input_required],\n        settings=FolderAnalyzerSettings(\n            base_directory=global_data_directory,\n            operations=[\n                FolderAnalysisOperation(\n                    operation_type="analyze_folder",\n                    path="dhenara_docs/docs",\n                    content_read_mode="none", # No content\n                ),\n                FolderAnalysisOperation(\n                    operation_type="analyze_folder",\n                    path="dhenara_docs/docs/dhenara-agent/getting-started",\n                    content_read_mode="full", #With full content\n                ),\n                FolderAnalysisOperation(\n                    operation_type="analyze_file",\n                    path="dhenara_docs/docs/dhenara-ai/introduction.md",\n                    content_read_mode="full", #With full content\n                ),\n                FolderAnalysisOperation(\n                    operation_type="analyze_file",\n                    path="dhenara_docs/docs/dhenara-agent/introduction.md",\n                    content_read_mode="full", #With full content\n                ),\n\n            ],\n        ),\n    ),\n)\n\n# 2. Code Generation Node\nimplementation_flow.node(\n    "code_generator",\n    AIModelNode(\n        settings=AIModelNodeSettings(\n            models=["claude-3-7-sonnet"],\n            system_instructions=[\n                # Role and Purpose\n                "You are a professional code implementation agent specialized in executing precise file operations.",\n                "Your task is to generate the exact file operations necessary to implement requested code changes - nothing more, nothing less.",\n                "Generate machine-executable operations that require zero human intervention.",\n                # Supported Operations\n                "ALLOWED OPERATIONS:",\n                "- create_file(file_path, content)",\n                "- delete_file(file_path)",\n                "- create_directory(directory_path)",\n                # Prohibited Operations\n                "PROHIBITED OPERATIONS (do not use):",\n                "- edit_file",\n                "- list_directory",\n                "- search_files",\n                "- get_file_metadata",\n                "- list_allowed_directories",\n                # Best Practices\n                "IMPLEMENTATION GUIDELINES:",\n                "1. For complete file replacement, use delete_file followed by create_file instead of a single edit_file.",\n                "2. Maintain the project\'s existing code style, indentation, and formatting conventions.",\n            ],\n            prompt=Prompt.with_dad_text(\n                text=(\n                    "## Task Description\\n"\n                    f"{task_description}"\n                    "## Repository Context\\n"\n                    "$expr{$hier{dynamic_repo_analysis}.outcome.results}\\n\\n"\n                    "## Implementation Requirements\\n"\n                    "1. Generate precise file operations that can be executed programmatically\\n"\n                    "2. Strictly follow instructions\\n"\n                    "3. Consider the entire context when making implementation decisions\\n"\n                    "## Output Format\\n"\n                    "Return a TaskImplementation object\\n"\n                ),\n            ),\n            model_call_config=AIModelCallConfig(\n                structured_output=TaskImplementation,\n                test_mode=True, # Start in test mode, and we will change this later\n                max_output_tokens=64000,\n                max_reasoning_tokens=4000,\n                reasoning=True,\n                timeout=1800.0,  # 30 minutes\n            ),\n        ),\n    ),\n)\n\n# 3. File Operation Node\nimplementation_flow.node(\n    "code_generator_file_ops",\n    FileOperationNode(\n        settings=FileOperationNodeSettings(\n            base_directory=global_data_directory,\n            operations_template=ObjectTemplate(\n                expression="$expr{ $hier{code_generator}.outcome.structured.file_operations }",\n            ),\n            stage=True,\n        ),\n    ),\n)\n\n'})}),"\n",(0,i.jsx)(n.p,{children:"The flow does three main things:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Read context files based on a predefined task specification"}),"\n",(0,i.jsx)(n.li,{children:"Generate code based on the task and context"}),"\n",(0,i.jsx)(n.li,{children:"Execute the generated file operations"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"agent-update",children:"Agent update"}),"\n",(0,i.jsxs)(n.p,{children:["Now you have defined the flow inside ",(0,i.jsx)(n.code,{children:"src/agents/autocoder/flows/implementation.py"}),". Let's update the agent file in\n",(0,i.jsx)(n.code,{children:"src/agents/autocoder/agent.py"})," with this flow:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from dhenara.agent.dsl import AgentDefinition\n\nfrom .flows.implementation import implementation_flow\n\nagent = AgentDefinition()\nagent.flow(\n    "main_flow",\n    implementation_flow,\n)\n\n'})}),"\n",(0,i.jsx)(n.h2,{id:"update-runners",children:"Update Runners"}),"\n",(0,i.jsxs)(n.p,{children:["Now we have defined the flow and added it to the agent. Next we need to setup the runtime parameters before running the\nagent. For now, you don't need to update anything in runners, as the pre-defined runner that was generated with the\n",(0,i.jsx)(n.code,{children:"dhenara create agent"})," command works for us as is. It will be in the path ",(0,i.jsx)(n.code,{children:"src/runners/autocoder.py"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"Here's what it contains for reference:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from dhenara.agent.dsl.events import EventType\nfrom dhenara.agent.run import RunContext\nfrom dhenara.agent.runner import AgentRunner\nfrom dhenara.agent.utils.helpers.terminal import (\n    print_component_completion,\n    print_node_completion,\n)\n\n# Select the agent to run, and import its definitions\nfrom src.agents.autocoder.agent import agent\nfrom src.agents.autocoder.handler import node_input_event_handler\nfrom src.runners.defs import project_root\n\n# Select an agent to run, assign it a root_id\nroot_component_id = "autocoder_root"\nagent.root_id = root_component_id\n\n# Create run context\nrun_context = RunContext(\n    root_component_id=root_component_id,\n    project_root=project_root,\n    observability_settings=None,  # pass observability_settings to enable tracing\n    run_root_subpath=None,  # "agent_autocoder" Useful to pass when you have multiple agents in the same projects.\n)\n\n\n# Register the event handlers\nrun_context.register_event_handlers(\n    handlers_map={\n        EventType.node_input_required: node_input_event_handler,\n        # Optional Notification events\n        EventType.node_execution_completed: print_node_completion,\n        EventType.component_execution_completed: print_component_completion,\n    }\n)\n\n# Create a runner\nrunner = AgentRunner(agent, run_context)\n\n# Use dhenara cli to run this as in an isolated context\n#  --  dhenara run agent <agent_name>\n\n'})}),"\n",(0,i.jsx)(n.h2,{id:"running-the-agent",children:"Running the agent"}),"\n",(0,i.jsxs)(n.p,{children:["Let's run this agent now. Remember that we have set ",(0,i.jsx)(n.code,{children:"test_mode=True"})," so the actual operations will not take place. But\nwe still want to make sure that we are sending the right context to the LLM."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"dhenara run agent autocoder\n"})}),"\n",(0,i.jsx)(n.p,{children:"This will show you a message like below:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"(.venv) $ dhenara run agent autocoder\n\u2713 Node dynamic_repo_analysis execution completed\n\u2713 autocoder_root execution completed\nAgent standard run completed successfully. Run ID: run_20250514_225955_98cb96\n\n\n\u2705 RUN COMPLETED SUCCESSFULLY\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Run ID: run_20250514_225955_98cb96\n  Artifacts location: /Users/<dad_project_repo_path>/dev_agents/runs/run_20250514_225955_98cb96\n\n\nLogs in /Users/<dad_project_repo_path>/dev_agents/runs/run_20250514_225955_98cb96/.trace/logs.jsonl\n\n(.venv) $\n"})}),"\n",(0,i.jsx)(n.p,{children:"Now let's look into the artifacts: Go to the artifacts directory inside the run dir. You will see a folder structure\nlike this:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"run_20240514_225955_98cb96\n\u251c\u2500\u2500 .trace\n\u2502   \u251c\u2500\u2500 dad_metadata.json\n\u2502   \u251c\u2500\u2500 logs.jsonl\n\u2502   \u251c\u2500\u2500 metrics.jsonl\n\u2502   \u2514\u2500\u2500 trace.jsonl\n\u251c\u2500\u2500 autocoder_root\n\u2502   \u2514\u2500\u2500 main_flow\n\u2502       \u2514\u2500\u2500 dynamic_repo_analysis\n\u2502           \u251c\u2500\u2500 outcome.json\n\u2502           \u2514\u2500\u2500 result.json\n\u2514\u2500\u2500 static_inputs\n"})}),"\n",(0,i.jsx)(n.p,{children:"Understand the folder names here:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.em,{children:"autocoder_root"}),": This is the ",(0,i.jsx)(n.em,{children:"root_component_id"})," defined inside the runner like\n",(0,i.jsx)(n.code,{children:'root_component_id = "autocoder_root"'})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.em,{children:"main_flow"}),": The element id added to ",(0,i.jsx)(n.em,{children:"implementation_flow"})," inside agent definition\n",(0,i.jsx)(n.code,{children:'agent.flow("main_flow", implementation_flow)'})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.em,{children:"dynamic_repo_analysis"}),": Node id of first node inside ",(0,i.jsx)(n.em,{children:"implementation_flow"}),"\n",(0,i.jsx)(n.code,{children:'implementation_flow.node("dynamic_repo_analysis", FolderAnalyzerNode(...'})]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["But wait, where are the folders for the second and third nodes with ids ",(0,i.jsx)(n.em,{children:"code_generator"})," and ",(0,i.jsx)(n.em,{children:"code_generator_file_ops"}),"\ninside ",(0,i.jsx)(n.em,{children:"implementation_flow"}),"? If you see them missing, it's because you haven't set credentials file correctly. Update\nthe ",(0,i.jsx)(n.code,{children:"dev_agents/.dhenara/.secrets/.credentials.yaml"}),", and keep entries for only the providers you use."]}),"\n",(0,i.jsx)(n.h3,{id:"debugging",children:"Debugging"}),"\n",(0,i.jsxs)(n.p,{children:["All the logs from the runs are kept inside the ",(0,i.jsx)(n.code,{children:".trace/logs.jsonl"})," in a jsonl format. If you haven't set the credentials\ncorrectly, when you open this log file, you will see error messages like below. The easiest way to search for errors is\nto search for ",(0,i.jsx)(n.code,{children:'"body": "ERROR'}),". The first error message will look like:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:'{"body": "ERROR:dhenara.ai.types.resource._resource_config:Error initializing API for provider \'google_vertex_ai\': 1 validation error for AIModelAPI\\ncredentials\\n  Value error ...}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"fix-and-run",children:"Fix and run"}),"\n",(0,i.jsx)(n.p,{children:"Once you update the credentials correctly, run the agent again:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"dhenara run agent autocoder\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"(.venv) $ dhenara run agent autocoder\n\u2713 Node dynamic_repo_analysis execution completed\n\u2713 Node code_generator execution completed\n\u2713 Node code_generator_file_ops execution completed\n\u2713 main_flow execution completed\n\u2713 autocoder_root execution completed\nAgent standard run completed successfully. Run ID: run_20250514_233729_f3cd51\n\n\n\u2705 RUN COMPLETED SUCCESSFULLY\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Run ID: run_20250514_233729_f3cd51\n  Artifacts location: .../dev_agents/runs/run_20250514_233729_f3cd51\n\n\nLogs in .../dev_agents/runs/run_20250514_233729_f3cd51/.trace/logs.jsonl\n\n\n(.venv) $\n"})}),"\n",(0,i.jsx)(n.p,{children:"Now you will see folders for all nodes inside the new artifact directory. If you've set up everything correctly, you'll\nsee this folder structure inside the run directory:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"run_20250514_233729_f3cd51\n\u251c\u2500\u2500 .trace\n\u2502   \u251c\u2500\u2500 dad_metadata.json\n\u2502   \u251c\u2500\u2500 logs.jsonl\n\u2502   \u251c\u2500\u2500 metrics.jsonl\n\u2502   \u2514\u2500\u2500 trace.jsonl\n\u251c\u2500\u2500 autocoder_root\n\u2502   \u2514\u2500\u2500 main_flow\n\u2502       \u251c\u2500\u2500 code_generator\n\u2502       \u2502   \u251c\u2500\u2500 outcome.json\n\u2502       \u2502   \u251c\u2500\u2500 result.json\n\u2502       \u2502   \u2514\u2500\u2500 state.json\n\u2502       \u251c\u2500\u2500 code_generator_file_ops\n\u2502       \u2502   \u251c\u2500\u2500 outcome.json\n\u2502       \u2502   \u2514\u2500\u2500 result.json\n\u2502       \u2514\u2500\u2500 dynamic_repo_analysis\n\u2502           \u251c\u2500\u2500 outcome.json\n\u2502           \u2514\u2500\u2500 result.json\n\u2514\u2500\u2500 static_inputs\n"})}),"\n",(0,i.jsx)(n.h2,{id:"understanding-artifacts",children:"Understanding artifacts"}),"\n",(0,i.jsxs)(n.p,{children:["We already saw logs in the above section. Similarly, if you enable tracing/metrics, you will see those inside the\n",(0,i.jsx)(n.code,{children:".trace"})," dir."]}),"\n",(0,i.jsxs)(n.p,{children:["For each node, which is in fact doing some ",(0,i.jsx)(n.em,{children:"operation"}),", there will be an artifacts directory within its component\nhierarchy. We have kept this hierarchy for 2 reasons:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["To do a ",(0,i.jsx)(n.code,{children:"rerun"})," on any run, from any node in any hierarchy by passing a ",(0,i.jsx)(n.code,{children:"--previous-run-id"})," and ",(0,i.jsx)(n.code,{children:"--entry-point"})," to\nthe run command. This might not look beneficial now, but when you create complex workflows, resuming a previous run\nfrom a specific node is quite useful as it saves money, time, and energy."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Here's the help output for the run command:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"(.venv) $ dhenara run agent  --help\nUsage: dhenara run agent [OPTIONS] IDENTIFIER\n\nOptions:\n  --project-root TEXT     Root directory of the project repo\n  --previous-run-id TEXT  ID of a previous execution to inherit context from\n  --entry-point TEXT      Specific point in the execution graph to begin from.\n                          Format can be a single element ID or a dot-notation\n                          path (e.g., 'agent_id.flow_id.node_id')\n  --help                  Show this message and exit.\n(.venv) $\n"})}),"\n",(0,i.jsx)(n.h3,{id:"artifact-files-inside-each-node",children:"Artifact files inside each node"}),"\n",(0,i.jsx)(n.p,{children:"Every node will have 2 artifact files:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"result.json"}),": The result of the node execution. This is a model dump of:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class NodeExecutionResult:\n    executable_type: ExecutableTypeEnum = Field(...)\n    node_identifier: NodeID = Field(...)\n    execution_status: ExecutionStatusEnum = Field(...)\n    input: NodeInputT | None = Field(default=None)\n    output: NodeOutputT | None = Field(default=None)\n    outcome: NodeOutcomeT | None = Field(default=None)\n    error: str | None = Field(default=None)\n    errors: list[str] | None = Field(default=None)\n    created_at: datetime = Field(...)\n"})}),"\n",(0,i.jsx)(n.p,{children:"where the input, output, and outcome are specific to nodes."}),"\n",(0,i.jsxs)(n.p,{children:["This is the result we refer to when using a ",(0,i.jsx)(n.code,{children:"$hier{node_id}"})," inside the DAD template."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"outcome.json"}),": This is just a convenience file. This file extracts the ",(0,i.jsx)(n.code,{children:"outcome"})," field of a node execution result\nand dumps it separately."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.admonition,{type:"tip",children:[(0,i.jsxs)(n.p,{children:["Whenever we refer to the ",(0,i.jsx)(n.em,{children:"outcome"})," field of a node inside a template, like\n",(0,i.jsx)(n.code,{children:"$expr{ $hier{code_generator}.outcome.structured.file_operations }"}),", it is the outcome field of ",(0,i.jsx)(n.code,{children:"result.json"}),", not the\noutcome saved inside the ",(0,i.jsx)(n.code,{children:"outcome.json"}),"."]}),(0,i.jsxs)(n.p,{children:["In other words, on a rerun, if you edit the ",(0,i.jsx)(n.code,{children:"outcome.json"}),", it will have NO effect, but if you edit the ",(0,i.jsx)(n.em,{children:"outcome"})," field\ninside ",(0,i.jsx)(n.code,{children:"result.json"}),", it will take effect in the next ",(0,i.jsx)(n.code,{children:"$hier{}"})," reference."]})]}),"\n",(0,i.jsx)(n.p,{children:"For an AIModelNode, there will be an extra file:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"state.json"}),": Contains the actual LLM API call parameters including the final prompt (after processing DAD templates\nif any). This is quite useful for debugging LLM API calls."]}),"\n"]}),"\n",(0,i.jsx)(n.h1,{id:"tutorial",children:"Tutorial"}),"\n",(0,i.jsx)(n.h2,{id:"analysing-node-artifacts-results",children:"Analysing Node artifacts results"}),"\n",(0,i.jsx)(n.p,{children:"Now let's go through the results of nodes."}),"\n",(0,i.jsx)(n.h3,{id:"folderanalyzernode",children:"FolderAnalyzerNode"}),"\n",(0,i.jsx)(n.p,{children:"FolderAnalyzerNode has a wide range of settings."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class FolderAnalyzerSettings:\n    base_directory: str\n    use_relative_paths: bool\n    allowed_directories: list[str]\n    operations: list[FolderAnalysisOperation]\n    operations_template: ObjectTemplate\n    fail_fast: bool\n\n# Whereas each operation is as below\nclass FolderAnalysisOperation(FileSystemAnalysisOperation):\n    operation_type: Literal[ "analyze_folder", "analyze_file", "find_files", "get_structure" ]\n    path: str\n    content_read_mode: Literal["none", "preview", "full", "structure"]\n    additional_gitignore_paths: list[str]\n'})}),"\n",(0,i.jsxs)(n.p,{children:["Open the ",(0,i.jsx)(n.em,{children:"outcome.json"})," file in ",(0,i.jsx)(n.code,{children:"runs/run_<run_id>/autocoder_root/main_flow/dynamic_repo_analysis"})," and make sure the\noutcome is as what you expect. For example, if the content mode is ",(0,i.jsx)(n.em,{children:"none"}),", you will see a the directory structure\ntraversed downwards without any file content. Also make sure that no unwanted files are getting added there. By default\nthis respects all the ",(0,i.jsx)(n.code,{children:".gitignore"})," files in the path it's traversing, but still make sure that any unexpected files are\nmentioned in the result."]}),"\n",(0,i.jsx)(n.h3,{id:"aimodelnode-node",children:"AIModelNode Node"}),"\n",(0,i.jsxs)(n.p,{children:["As we have run this node in test*mode, this will not have any valid outcome. But for AIModelNode nodes, there is an\nadditional ",(0,i.jsx)(n.em,{children:"state.json"})," file. Open this file and make sure the API call parameters are as you expect (except test_mode).\nOpen the ",(0,i.jsx)(n.em,{children:"outcome.json"})," file in ",(0,i.jsx)(n.code,{children:"runs/run*<run_id>/autocoder_root/main_flow/code_generator/state.json"})," and analyze the\nparameters."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "ai_model": "claude-3-7-sonnet",\n  "api": "anthropic",\n  "model_call_config": {\n    "streaming": false,\n    "max_output_tokens": 64000,\n    "reasoning": true,\n    "max_reasoning_tokens": 4000,\n    "options": {},\n    "structured_output": {....},\n    "metadata": {},\n    "timeout": 1800.0,\n    "retries": 3,\n    "retry_delay": 1.0,\n    "max_retry_delay": 10.0,\n    "test_mode": true\n  },\n  "prompt": "## Task Description\\nUp....",\n  "context": [],\n  "instructions": [\n    "You ... conventions."\n  ]\n}\n'})}),"\n",(0,i.jsxs)(n.p,{children:["If you inspect the prompt, the template expression ",(0,i.jsx)(n.code,{children:'"$expr{$hier{dynamic_repo_analysis}.outcome.results}\\n\\n"'})," is\nproperly rendered with the folder analysis node outcome as a string."]}),"\n",(0,i.jsx)(n.h3,{id:"fileoperationnode",children:"FileOperationNode"}),"\n",(0,i.jsx)(n.p,{children:"We will not analyze this now, as this node has a dependency on its previous AIModelNode, and it was in test_mode."}),"\n",(0,i.jsxs)(n.p,{children:["Once you are happy with the node results/state, it's time to disable the ",(0,i.jsx)(n.em,{children:"test_mode"})," and make actual API calls."]}),"\n",(0,i.jsx)(n.h2,{id:"run-in-live-mode",children:"Run in Live mode"}),"\n",(0,i.jsxs)(n.p,{children:["In your flow inside ",(0,i.jsx)(n.code,{children:"src/agents/autocoder/flows/implementation.py"})," disable the ",(0,i.jsx)(n.em,{children:"test_mode"})," inside ",(0,i.jsx)(n.code,{children:"AIModelNode"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"             model_call_config=AIModelCallConfig(\n                structured_output=TaskImplementation,\n                test_mode=False, # Disable Test Mode, or delete this line as its disabled by default\n                max_output_tokens=64000,\n                max_reasoning_tokens=4000,\n                reasoning=True,\n                timeout=1800.0,  # 30 minutes\n            ),\n"})}),"\n",(0,i.jsx)(n.p,{children:"and again run the flow."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"dhenara run agent autocoder\n"})}),"\n",(0,i.jsx)(n.p,{children:"This time, after the node dynamic_repo_analysis got completed, there is a slight delay before showing other node status.\nIt's because the AIModelNode is making an API call and waiting for its results."}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["DAD currently does not support streaming, but we will add it soon. The ",(0,i.jsx)(n.code,{children:"dhenara-ai"})," package has a lot of cool features\nfor streaming, and we will integrate it to DAD soon."]})}),"\n",(0,i.jsx)(n.p,{children:"Once the execution is completed, again go through the results."}),"\n",(0,i.jsx)(n.h2,{id:"final-results",children:"Final Results"}),"\n",(0,i.jsxs)(n.p,{children:["If the execution was successfully completed, you should get the new/updated files in your repos under\n",(0,i.jsx)(n.code,{children:"runs/global_data"}),". The first thing you could check is if something happened \ud83d\ude42."]}),"\n",(0,i.jsx)(n.p,{children:"In our case, we were just asking it to update a readme file. So we will do below:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'$ cd dev_agents/runs/global_data/dhenara_docs\n$ git status\nOn branch master\nYour branch is up to date with \'origin/master\'.\n\nChanges not staged for commit:\n  (use "git add <file>..." to update what will be committed)\n  (use "git restore <file>..." to discard changes in working directory)\n        modified:   README.md\n\nno changes added to commit (use "git add" and/or "git commit -a")\n$\n'})}),"\n",(0,i.jsx)(n.p,{children:"Yes, the files are generated for us."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"diff --git a/README.md b/README.md\nindex e36d60d..fbd5a9f 100644\n--- a/README.md\n+++ b/README.md\n@@ -1,5 +1,96 @@\n-# Dhenara AI Documentation\n+# Dhenara Documentation\n\n-This repository contains the documentation for the Dhenara AI & Dhenara Agent frameworks.\n+Welcome to the official documentation repository for Dhenara products! This repository contains comprehensive documentation for the Dhenara ecosystem.\n\n-Visit [Dhenara Docs](https://docs.dhenara.com/) to view the documentation.\n+## What is Dhenara?\n+\n+Dhenara provides a suite of open-source tools for working with AI models and building sophisticated AI agents:\n+\n+### Dhenara-AI\n\n...\n\n"})}),"\n",(0,i.jsx)(n.p,{children:"You got what you want. But still let's analyze the node results in live mode so that you understand the framework\nbetter."}),"\n",(0,i.jsx)(n.p,{children:"The FolderAnalyserNode result is exactly same as previous, so we will skip it now."}),"\n",(0,i.jsx)(n.admonition,{type:"warning",children:(0,i.jsx)(n.p,{children:"Make sure you are looking into the correct (latest) run directory."})}),"\n",(0,i.jsx)(n.h3,{id:"aimodelnode-node-1",children:"AIModelNode Node"}),"\n",(0,i.jsxs)(n.p,{children:["In the ",(0,i.jsx)(n.code,{children:"runs/run_<run_id>/autocoder_root/main_flow/code_generator/outcome.json"}),", you should see the ",(0,i.jsx)(n.em,{children:"structured"})," output\nin the schema we requested to the model via TaskImplementation"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'{\n  "structured": {\n    "task_id": null,\n    "file_operations": [\n      {\n        "type": "create_file",\n        "path": "dhenara_docs/README.md",\n        "paths": null,\n        "content": "# Dhenara Documentation\\n\\nWelcome to ... additional examples.\\n",\n        "edits": null,\n        "dry_run": false,\n        "source": null,\n        "destination": null,\n        "search_config": null\n      }\n    ],\n    "execution_commands": null,\n    "verification_commands": null\n  },\n  "files": []\n}\n'})}),"\n",(0,i.jsxs)(n.p,{children:["If you still don't see a proper ",(0,i.jsx)(n.code,{children:"structured"})," outcome, then there are some issues and you will NOT see successful file\nupdates. To see what happened, look into the ",(0,i.jsx)(n.code,{children:"result.json"})," file in the AIModelNode artifacts."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "executable_type": "flow_node",\n  "node_identifier": "code_generator",\n  "execution_status": "completed",\n  "output": {\n    "data": {\n      "response": {\n        "status": {\n          "status": "response_received_success",\n          "api_provider": "anthropic",\n          "model": "claude-3-7-sonnet",\n          "message": "Output generated",\n          "code": "success",\n          "http_status_code": 200\n        },\n        "chat_response": {\n          "model": "claude-3-7-sonnet-latest",\n          "provider": "anthropic",\n          "api_provider": "anthropic",\n          "usage": {\n            "total_tokens": 11911,\n            "prompt_tokens": 10388,\n            "completion_tokens": 1523\n          },\n          "usage_charge": {\n            "cost": 0.054009\n          },\n          "choices": [\n            {\n              "index": 0,\n              "finish_reason": "tool_use",\n              "contents": [\n                {\n                  "index": 0,\n                  "metadata": {\n                    "signature": "Er...C"\n                  },\n                  "storage_metadata": {},\n                  "custom_metadata": {},\n                  "type": "reasoning",\n                  "role": "assistant",\n                  "thinking_text": "Based on the task description, I need to update the README file with relevant content...."\n                },\n                {\n                  "index": 1,\n                  "metadata": {},\n                  "storage_metadata": {},\n                  "custom_metadata": {},\n                  "type": "text",\n                  "role": "assistant",\n                  "text": "Looking at the repository context, I need to create a README.md file that provides an overview of the Dhenara documentation repository. Let me implement this task."\n                },\n                {\n                  "index": 2,\n                  "metadata": {},\n                  "storage_metadata": {},\n                  "custom_metadata": {},\n                  "type": "structured_output",\n                  "role": "assistant",\n                  "structured_output": {\n                    "config": "EDITED: You will see the config we requested",\n                    "structured_data": {\n                      "task_id": null,\n                      "file_operations": [\n                        {\n                          "type": "create_file",\n                          "path": "dhenara_docs/README.md",\n                          "paths": null,\n                          "content": "# Dhenara Documentation\\n\\nWelcome to ... examples.\\n",\n                          "edits": null,\n                          "dry_run": false,\n                          "source": null,\n                          "destination": null,\n                          "search_config": null\n                        }\n                      ],\n                      "execution_commands": null,\n                      "verification_commands": null\n                    }\n                  }\n                }\n              ],\n              "metadata": {}\n            }\n          ],\n          "metadata": {\n            "streaming": false,\n            "duration_seconds": 0,\n            "provider_metadata": {\n              "id": "msg_018etqD3RAH7n3qcVSaFjbvR"\n            }\n          }\n        }\n      }\n    },\n    "metadata": {}\n  },\n  "outcome": "EDITED: You will see the same outcome as in `outcome.json` file",\n  "created_at": "2025-05-15T10:07:20.260995"\n}\n'})}),"\n",(0,i.jsx)(n.h4,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsxs)(n.p,{children:["If you don't see a ",(0,i.jsx)(n.em,{children:"structured"})," in any of the response content/choices, the LLM was not responding with the correct\nstructure you requested. Some possible scenarios are:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["LLM Context Window reached while generation. You will see it in ",(0,i.jsx)(n.code,{children:'"finish_reason": "max_token"'}),". You will need to\nreduce the input tokens by reading fewer files or increase output tokens in the ",(0,i.jsx)(n.em,{children:"AIModelCallConfig"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["LLM didn't generate the correct schema we requested. Here inside ",(0,i.jsx)(n.code,{children:"structured_output"})," in the result, you will see the\n",(0,i.jsx)(n.code,{children:"structured_data"})," as null, but there will be a ",(0,i.jsx)(n.code,{children:"parse_error"})," which describes the parsing error. One quick try you\ncould give here is to copy the raw_data and parse error, paste it in a chatbot and ask it to correct it, and then\nmodify structured_data field in ",(0,i.jsx)(n.code,{children:"result.json"})," and rerun agent from this node."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"fileoperationnode-1",children:"FileOperationNode"}),"\n",(0,i.jsxs)(n.p,{children:["As you have seen a successful ",(0,i.jsx)(n.em,{children:"outcome"})," in the ",(0,i.jsx)(n.em,{children:"dynamic_repo_analysis"})," node, the FileOperationNode setting will\ncorrectly pick the operations from operation_template."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# 3. File Operation Node\nimplementation_flow.node(\n    "code_generator_file_ops",\n    FileOperationNode(\n        settings=FileOperationNodeSettings(\n            base_directory=global_data_directory,\n            operations_template=ObjectTemplate(  #NOTE: we had given the operations as a DAD template as below\n                expression="$expr{ $hier{code_generator}.outcome.structured.file_operations }",\n            ),\n            stage=True,\n        ),\n    ),\n)\n'})}),"\n",(0,i.jsxs)(n.p,{children:["And the outcome of file operations is in\n",(0,i.jsx)(n.code,{children:"runs/run_<run_id>/autocoder_root/main_flow/code_generator_file_ops/outcome.json"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "base_directory": "path/to/dev_agents/runs/global_data",\n  "results": [\n    {\n      "type": "create_file",\n      "path": "dhenara_docs/README.md",\n      "success": true\n    }\n  ]\n}\n'})}),"\n",(0,i.jsx)(n.p,{children:"Hurray, you have successfully implemented your first CLI agent using DAD. In the next part, we will enhance this further\nby avoiding hard-coded inputs in this flow."}),"\n",(0,i.jsx)(n.h2,{id:"whats-next",children:"What's Next?"}),"\n",(0,i.jsxs)(n.p,{children:["In ",(0,i.jsx)(n.a,{href:"/dhenara-agent/guides/tutorials/single-shot-coder/part-2",children:"Part 2: Planning Flow"}),", we'll enhance our coding assistant by avoiding hard coded inputs and taking\nlive inputs on run."]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}}}]);