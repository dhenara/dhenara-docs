"use strict";(self.webpackChunkdhenara_docs=self.webpackChunkdhenara_docs||[]).push([[1771],{825:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>c,frontMatter:()=>s,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"dhenara-ai/samples/text-gen/text-gen","title":"Text Generation","description":"Smallest \u201chello world\u201d for text generation.","source":"@site/docs/dhenara-ai/samples/text-gen/text-gen.md","sourceDirName":"dhenara-ai/samples/text-gen","slug":"/dhenara-ai/samples/text-gen/","permalink":"/dhenara-ai/samples/text-gen/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Text Generation"},"sidebar":"dhenaraAiSidebar","previous":{"title":"Foundation Models","permalink":"/dhenara-ai/features/models"},"next":{"title":"Async Text Generation","permalink":"/dhenara-ai/samples/text-gen/text-gen-async"}}');var o=t(4848),r=t(8453);const s={title:"Text Generation"},i="Text Generation",l={},d=[{value:"Reasoning / thinking models",id:"reasoning--thinking-models",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"text-generation",children:"Text Generation"})}),"\n",(0,o.jsx)(n.p,{children:"Smallest \u201chello world\u201d for text generation."}),"\n",(0,o.jsxs)(n.p,{children:["For a full runnable script, see ",(0,o.jsx)(n.code,{children:"packages/dhenara_ai/examples/01_text_generation.py"}),"."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import os\n\nfrom dhenara.ai import AIModelClient\nfrom dhenara.ai.types import AIModelAPI, AIModelAPIProviderEnum, AIModelCallConfig, AIModelEndpoint\nfrom dhenara.ai.types.genai.foundation_models.anthropic.chat import ClaudeSonnet45\n\n\napi = AIModelAPI(\n    provider=AIModelAPIProviderEnum.ANTHROPIC,\n    api_key=os.environ["ANTHROPIC_API_KEY"],\n)\n\nendpoint = AIModelEndpoint(api=api, ai_model=ClaudeSonnet45)\n\nclient = AIModelClient(\n    model_endpoint=endpoint,\n    config=AIModelCallConfig(\n        max_output_tokens=400,\n        streaming=False,\n    ),\n    is_async=False,\n)\n\nresponse = client.generate(\n    prompt="What are three ways to improve productivity?",\n    instructions=["Be specific and actionable."],\n)\n\nassert response.chat_response\nprint(response.chat_response.text())\n\n# Optional metrics (if enabled)\nprint(response.chat_response.usage)\nprint(response.chat_response.usage_charge)\n'})}),"\n",(0,o.jsx)(n.h2,{id:"reasoning--thinking-models",children:"Reasoning / thinking models"}),"\n",(0,o.jsxs)(n.p,{children:["If you enable reasoning on a reasoning-capable model, you can also read any exposed \u201cthinking text\u201d via ",(0,o.jsx)(n.code,{children:"reasoning()"}),"."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from dhenara.ai import AIModelClient\nfrom dhenara.ai.types import AIModelCallConfig\n\n\nclient = AIModelClient(\n    model_endpoint=endpoint,\n    config=AIModelCallConfig(\n        reasoning=True,\n        reasoning_effort="medium",\n        max_reasoning_tokens=800,\n        streaming=False,\n    ),\n    is_async=False,\n)\n\nresponse = client.generate(prompt="Summarize time blocking in 4 bullets.")\n\nassert response.chat_response\nprint(response.chat_response.reasoning() or "")\nprint(response.chat_response.text())\n'})})]})}function c(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(p,{...e})}):p(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>i});var a=t(6540);const o={},r=a.createContext(o);function s(e){const n=a.useContext(r);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),a.createElement(r.Provider,{value:n},e.children)}}}]);